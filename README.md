# Performance-Analytics-Final
This project represents the culmination of the work developed during the course, combining data collection, parsing, analysis, and visualization. The primary objective was to extract meaningful insights from "performance" data, utilizing a combination of automated data collection techniques, parsing methods, and statistical analysis.

## Key Components

### 1. Data Source
The data source comprises "performance" datasets collected from web scraping methods and APIs. The objective was to explore significant questions, such as:
- Are there measurable correlations between certain variables?
- What statistical patterns can be observed in the data?

### 2. Crawler Implementation
- **Tools Used**: Python, Requests, BeautifulSoup
- The crawler was implemented to automatically collect data from web pages, ensuring scalability to handle multiple HTML files.
- **API Integration**: For structured data, APIs were utilized to streamline the acquisition process.

### 3. Data Parser
- Extracted key performance metrics from HTML tables.
- Parsed rows and columns of interest into structured formats (e.g., CSV).
- **Libraries**: Python, BeautifulSoup, Pandas.

### 4. Results and Visualizations
The results of the empirical analysis revealed key insights, presented using visualizations:
- **Empirical Probability Distributions**: Highlighted the distribution of key metrics.
- **Correlation Scatter Plots**: Demonstrated relationships between selected variables.
- **Key Deductions**:
  - Significant trends in the data indicate potential correlations.
  - Certain variables align with known statistical laws (e.g., linear regression trends).

### 5. Discussion & Conclusions
This project addressed core research questions and demonstrated the power of automated data collection and analysis. 
- **Limitations**: Data quality and sparsity limited some conclusions.
- **Future Work**: Additional data sources and refined analysis techniques could provide more comprehensive results.

## Tools and Libraries Used
- **Python**: Programming language
- **BeautifulSoup**: Web scraping
- **Pandas**: Data processing
- **Matplotlib**: Data visualization
- **NumPy**: Numerical computations

## Key Visualizations
1. **Histograms**: Empirical distributions.
2. **Scatter Plots**: Correlation between variables.
3. **Multi-Panel Figures**: Combined visualizations for comprehensive insights.
